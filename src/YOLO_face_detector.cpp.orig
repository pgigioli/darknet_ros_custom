#include "ROS_interface.h"
#include <geometry_msgs/Point.h>
#include <vector>
#include <iostream>
#include <pthread.h>
#include <face_tracker/rect.h>
#include <face_tracker/templMatch.h>
#include <face_tracker/imageArray.h>
#include <std_msgs/Int8.h>

extern "C" {
  #include "box.h"
}

// initialize YOLO functions that are called in this script
extern "C" ROS_box *demo_yolo(char *cfgfile, char *weightfile, float thresh, int cam_index,
				char *filename);
extern "C" void load_network(char *cfgfile, char *weightfile, float thresh, int cam_index);

using namespace std;
using namespace cv;
using namespace cv::gpu;

// define demo_yolo inputs. cam_index and filename are placeholders and have arbitrary values
char *cfg = "/media/ubuntu/darknet/cfg/yolo-tiny_heads.cfg";
//char *weights = "/media/ubuntu/darknet/face_detector_weights/yolo-tiny_heads_v5_3000.weights";
//char *weights = "/media/ubuntu/darknet/face_detector_weights/yolo-tiny_heads_v7_4000.weights";
char *weights = "/media/ubuntu/darknet/face_detector_weights/yolo-tiny_heads_v8_6000.weights";
float thresh = 0.2;
int cam_index = 0;
char *filename = "/media/ubuntu/darknet/data/person.jpg";

// define global variables
static const std::string OPENCV_WINDOW = "YOLO face detection";
int FRAME_W;
int FRAME_H;
int FRAME_AREA;
int NUM_FACES;
Mat cv_ptr_copy;
geometry_msgs::Point focal_point;
vector<Mat> templates;
vector<Rect> searchROIcoordinates;
vector<int> class_list;
float TEMPL_SCALE = 0.5; //0.7
float ROI_SCALE = 3.0; //3.0
int FRAME_COUNT = 0;
int FACE_EXISTS = 0;

// define a function that will replace CvVideoCapture.
// This function is called in yolo_kernels and allows YOLO to receive the ROS image
// message as an IplImage
IplImage* get_Ipl_image()
{
  IplImage* ROS_img = new IplImage(cv_ptr_copy);
  return ROS_img;
}

class yoloFaceDetector
{
  ros::NodeHandle nh;

  image_transport::ImageTransport it;
  image_transport::Subscriber image_sub;
  ros::Publisher ROI_coordinate_pub;
  ros::Publisher template_match_pub;
  ros::Publisher found_object_pub;
  ros::Publisher cropped_faces_pub;
  //image_transport::Publisher cropped_faces_pub;

public:
  yoloFaceDetector() : it(nh)
  {
	image_sub = it.subscribe("/usb_cam/image_raw", 1,
	  &yoloFaceDetector::callback,this);
	ROI_coordinate_pub = nh.advertise<geometry_msgs::Point>("ROI_coordinate", 1);
	template_match_pub = nh.advertise<face_tracker::templMatch>("YOLO_templates", 1);
	found_object_pub = nh.advertise<std_msgs::Int8>("found_object", 1);
	cropped_faces_pub = nh.advertise<face_tracker::imageArray>("cropped_faces", 1);

	namedWindow(OPENCV_WINDOW, WINDOW_NORMAL);
  }

  ~yoloFaceDetector()
  {
	destroyWindow(OPENCV_WINDOW);
  }

private:
  void publishCroppedImgs(vector<Mat> croppedFacesArray, int num)
  {
	face_tracker::imageArray img_msg_array;

	// convert cropped faces to image messages and publish
	for (int i = 0; i < num; i++) {
           cv_bridge::CvImage img_bridge;
           sensor_msgs::Image img_msg;
           std_msgs::Header header;
           header.seq = i;
           header.stamp = ros::Time::now();
           img_bridge = cv_bridge::CvImage(header, sensor_msgs::image_encodings::RGB8,
		 croppedFacesArray[i]);
           img_bridge.toImageMsg(img_msg);
   	   img_msg_array.images.push_back(img_msg);
	}
        cropped_faces_pub.publish(img_msg_array);
  }

  Rect getCroppedDimensions(ROS_box boxes, float scale)
  {
	int xmin = (boxes.x - scale*boxes.w/2)*FRAME_W;
	int ymin = (boxes.y - scale*boxes.h/2)*FRAME_H;
	int xmax = (boxes.x + scale*boxes.w/2)*FRAME_W;
	int ymax = (boxes.y + scale*boxes.h/2)*FRAME_H;

	if (xmin < 0) xmin = 0;
	if (ymin < 0) ymin = 0;
	if (xmax > FRAME_W) xmax = FRAME_W;
	if (ymax > FRAME_H) ymax = FRAME_H;

	Rect cropDim = Rect(xmin, ymin, (xmax - xmin), (ymax - ymin));
	return cropDim;
  }

  void getTemplates(ROS_box *boxes, Mat input_frame)
  {
	Mat full_frame = input_frame.clone();

	class_list.clear();
        templates.clear();
	searchROIcoordinates.clear();

	int num = boxes[0].num;
	float scale = 0.15;

	for (int i = 0; i < num; i++)
	{
	  Rect template_size = getCroppedDimensions(boxes[i], TEMPL_SCALE);
	  Rect searchROI_rect = getCroppedDimensions(boxes[i], ROI_SCALE);
	  class_list.push_back(boxes[i].Class);

	  searchROIcoordinates.push_back(searchROI_rect);
	  templates.push_back(full_frame(template_size));
	}

	if (num > 0) {
	  for (int i = 0; i < num; i++) {
	    stringstream ss;
	    ss << "template " << i;
	    string window_name = ss.str();
	    //imshow(window_name, templates[i]);
	    //waitKey(3);

	    stringstream ss2;
	    ss2 << "search ROI " << i;
	    string window_name2 = ss2.str();
	    //imshow(window_name2, full_frame(searchROIcoordinates[i]));
	    //waitKey(3);
	  }
	}
	return;
  }
/*
  void runTemplateMatching(Mat cv_ptr_copy, vector<Mat> templates, vector<Rect> searchROIcoordinates)
  {
	Mat input_frame = cv_ptr_copy.clone();

	Mat searchROI = input_frame.clone()(searchROIcoordinates[0]);
	Mat matchingResult;

	matchTemplate(searchROI, templates[0], matchingResult, CV_TM_SQDIFF_NORMED);
	normalize(matchingResult, matchingResult, 0, 1, NORM_MINMAX, -1, Mat());

	double min, max;
	Point minLoc, maxLoc;
	minMaxLoc(matchingResult, &min, &max, &minLoc, &maxLoc);

	// convert template dimensions into an ROS_box and expand it back to original cropped dimensions
	ROS_box templ_bbox;
	templ_bbox.w = float(templates[0].cols)/float(FRAME_W);
	templ_bbox.h = float(templates[0].rows)/float(FRAME_H);
	templ_bbox.x = float(minLoc.x + searchROIcoordinates[0].x + templates[0].cols/2)/float(FRAME_W);
	templ_bbox.y = float(minLoc.y + searchROIcoordinates[0].y + templates[0].rows/2)/float(FRAME_H);

	// update search ROI coordinates
	searchROIcoordinates[0] = getCroppedDimensions(templ_bbox, ROI_SCALE);

	// convert template size back to original cropped dimensions and save bbox
	Rect bbox = getCroppedDimensions(templ_bbox, 1/TEMPL_SCALE);

	// draw template matched bbox
	Point topLeftCorner = Point(bbox.x, bbox.y);
	Point botRightCorner = Point(bbox.x + bbox.width, bbox.y + bbox.height);
	rectangle(input_frame, topLeftCorner, botRightCorner, Scalar(255), 2);

	imshow("template match", input_frame);
	waitKey(3);
	return;
  }
*/
  void runYOLO(Mat cv_ptr_copy)
  {
	Mat input_frame = cv_ptr_copy.clone();

	// run yolo and get bounding boxes for faces
        ROS_box *boxes = demo_yolo(cfg, weights, thresh, cam_index, filename);

        // get the number of bounding boxes found
        int num = boxes[0].num;

	Point topLeftCorner;
	Point botRightCorner;

	// if at least one bbox found, define center point and draw box
        if (num != 0 && num >= 0  && num <= 50) {
	  FACE_EXISTS = 1;
	  NUM_FACES = num;

          std_msgs::Int8 msg;
          msg.data = 1;
          found_object_pub.publish(msg);

	  // get templates and search ROI rectangles for template matching
	  getTemplates(boxes, input_frame);

          focal_point.x = boxes[0].x*FRAME_W;
          focal_point.y = boxes[0].y*FRAME_H;
	  focal_point.z = 0.0;
          float largest_area = boxes[0].h*boxes[0].w*FRAME_AREA;

	  topLeftCorner = Point((boxes[0].x - boxes[0].w/2)*FRAME_W, (boxes[0].y - boxes[0].h/2)*FRAME_H);
	  botRightCorner = Point((boxes[0].x + boxes[0].w/2)*FRAME_W, (boxes[0].y + boxes[0].h/2)*FRAME_H);
	  rectangle(input_frame, topLeftCorner, botRightCorner, Scalar(255,255,0), 2);

	  // create array to hold cropped images of all faces found
	  vector<Mat> croppedFacesArray;
	  croppedFacesArray.clear();

	  // add first face found to face array
	  Rect croppedFace = Rect(topLeftCorner.x, topLeftCorner.y,
	 	boxes[0].w*FRAME_W, boxes[0].h*FRAME_H);
	  Mat cropped_frame = cv_ptr_copy.clone()(croppedFace);
	  croppedFacesArray.push_back(cropped_frame);

          // if additional bboxes found, define their centers, draw the boxes, and check for largest box
          if (num > 1) {
            for (int i=1; i < num; i++) {

		// draw the additional boxes
		topLeftCorner = Point((boxes[i].x - boxes[i].w/2)*FRAME_W, (boxes[i].y - boxes[i].h/2)*FRAME_H);
          	botRightCorner = Point((boxes[i].x + boxes[i].w/2)*FRAME_W, (boxes[i].y + boxes[i].h/2)*FRAME_H);
          	rectangle(input_frame, topLeftCorner, botRightCorner, Scalar(255,255,0), 2);

	        // add additional faces to face array
	        croppedFace = Rect(topLeftCorner.x, topLeftCorner.y, boxes[i].w*FRAME_W,
			boxes[i].h*FRAME_H);
		cropped_frame = cv_ptr_copy.clone()(croppedFace);
		croppedFacesArray.push_back(cropped_frame);

		// check for the largest box
                if (boxes[i].h*boxes[i].w*FRAME_AREA > largest_area + largest_area*0.1)
                {
                        largest_area = boxes[i].h*boxes[i].w*FRAME_AREA;
                        focal_point.x = boxes[i].x*FRAME_W;
                        focal_point.y = boxes[i].y*FRAME_H;
                }
            }
          }

	  // call function to convert faces to msg and publish
	  publishCroppedImgs(croppedFacesArray, num);

	  // draw focal point on face of interest
          cout << "center: " << focal_point.x << ", " << focal_point.y << endl;

          Point face_center(focal_point.x, focal_point.y);
          circle(input_frame, face_center, 2, Scalar(255,0,255), 2, 8, 0);

          ROI_coordinate_pub.publish(focal_point);

	  // iterate through the bounding boxes and reset them to zero
          for (int i=0; i < num; i++) {
    	    boxes[i].x = 0;
            boxes[i].y = 0;
          }
        }
	else {
	  FACE_EXISTS = 0;
          std_msgs::Int8 msg;
          msg.data = 0;
          found_object_pub.publish(msg);
	  //focal_point.z = 1;
	  //ROI_coordinate_pub.publish(focal_point);
	}

        imshow(OPENCV_WINDOW, input_frame);
        cv::waitKey(3);
  }
/*
  static void * thread_templateMatching(void *ptr)
  {
	((yoloFaceDetector *) ptr)->runTemplateMatching(cv_ptr_copy, templates, searchROIcoordinates);
	return NULL;
  }

  static void * thread_YOLO(void *ptr)
  {
	((yoloFaceDetector *) ptr)->runYOLO(cv_ptr_copy);
	return NULL;
  }
*/
  void callback(const sensor_msgs::ImageConstPtr& msg)
  {

  	cout << "usb image received" << endl;

 	cv_bridge::CvImagePtr cv_ptr;

	try {
	  cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
  	}
  	catch (cv_bridge::Exception& e) {
	  ROS_ERROR("cv_bridge exception: %s", e.what());
	  return;
  	}

	if (cv_ptr) {
	  cv_ptr_copy = cv_ptr->image.clone();

	  if (FRAME_COUNT == 0) {

		runYOLO(cv_ptr_copy);

		if (FACE_EXISTS == 1) {
		  // create message with templates and search ROI coordinates
		  face_tracker::templMatch templ_match_msg;

		  templ_match_msg.scale = TEMPL_SCALE;
		  templ_match_msg.num = NUM_FACES;

		  // iterate through number of templates and add template and search ROI
		  // coordinates to template matching message
		  for (int i = 0; i < NUM_FACES; i++) {
		  	cv_bridge::CvImage templ_bridge;
		  	sensor_msgs::Image templ_msg;
		  	std_msgs::Header templ_header;
		  	templ_header.seq = 0;
		  	templ_header.stamp = ros::Time::now();
		  	templ_bridge = cv_bridge::CvImage(templ_header,
				sensor_msgs::image_encodings::BGR8, templates[i]);
		  	templ_bridge.toImageMsg(templ_msg);
		  	templ_match_msg.templates.push_back(templ_msg);

                        templ_match_msg.classes.push_back(class_list[i]);

		  	face_tracker::rect ROI_msg;
		  	ROI_msg.x = searchROIcoordinates[i].x;
		  	ROI_msg.y = searchROIcoordinates[i].y;
		  	ROI_msg.w = searchROIcoordinates[i].width;
		  	ROI_msg.h = searchROIcoordinates[i].height;
		  	templ_match_msg.ROIcoords.push_back(ROI_msg);
		  }

		  // send array of templates and array of ROI coordinates to
		  // template matching function
		  template_match_pub.publish(templ_match_msg);
		}
	  }
	  else {
	  	//runTemplateMatching(cv_ptr_copy, templates, searchROIcoordinates);
	  }
	  //FRAME_COUNT++;
	  if (FRAME_COUNT == 1) FRAME_COUNT = 0;
  	}
 	return;
  }
};

int main(int argc, char** argv)
{
  ros::init(argc, argv, "ROS_interface");

  ros::param::get("/usb_cam/image_width", FRAME_W);
  ros::param::get("/usb_cam/image_height", FRAME_H);
  FRAME_AREA = FRAME_W * FRAME_H;

  load_network(cfg, weights, thresh, cam_index);

  yoloFaceDetector yfd;
  ros::spin();
  return 0;
}
